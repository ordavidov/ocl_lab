{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb13acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "from dataclasses import dataclass, field, InitVar\n",
    "from typing import Any\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import doframework as dof\n",
    "from doframework.core.pwl import PWL\n",
    "from doframework.core.sampler import D_sampler as sampler\n",
    "from doframework.core.triangulation import box_iterator\n",
    "from doframework.core.hit_and_run import in_domain\n",
    "from doframework.core.utils import sample_standard_simplex, incidence\n",
    "from doframework.core.storage import Storage\n",
    "from doframework.core.inputs import get_configs\n",
    "\n",
    "tol = 1e-8 # tolerance to near 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d490dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulate(fpoints: np.array, opoints: np.array, fvals: np.array, ovals: np.array):\n",
    "    \n",
    "    assert all([fpoints.shape[0]==fvals.flatten().size,opoints.shape[0]==ovals.flatten().size]), 'Length of values array should match the number of row vectors.'\n",
    "\n",
    "    m = fpoints.min()\n",
    "    M = fpoints.max()\n",
    "\n",
    "    olift = np.hstack([opoints,(np.random.rand(opoints.shape[0])*(M-m)+m)[:,None]])\n",
    "    flift = np.hstack([fpoints,(np.random.rand(fpoints.shape[0])*(M-m)+11*(M-m)+m)[:,None]]) \n",
    "\n",
    "    P = np.vstack([opoints,fpoints])\n",
    "    _, unique_indices = np.unique(P, axis=0, return_index=True) \n",
    "    Plift = np.vstack([olift,flift])[unique_indices]\n",
    "\n",
    "    view_point = np.concatenate([P.mean(axis=0),np.array([m-1000*(M-m)])]) \n",
    "    envelope = ConvexHull(np.vstack([np.atleast_2d(view_point),Plift]),qhull_options='QG0')\n",
    "    good_indices = envelope.simplices[envelope.good]\n",
    "    fPs = envelope.points[good_indices,:][:,:,:-1]\n",
    "\n",
    "    V = np.concatenate([ovals,fvals])[unique_indices]\n",
    "    fVs = V[:,None][good_indices-1].reshape(*good_indices.shape) # view point at index 0\n",
    "\n",
    "    oin = [np.all(incidence(opoints,fp).any(axis=0)) for fp in fPs]\n",
    "    oPs = fPs[oin]\n",
    "    oVs = fVs[oin]\n",
    "\n",
    "    if oPs.size == 0: # when fail to catch omega lower envelope\n",
    "        oPs, oVs = fPs, fVs\n",
    "\n",
    "    return fPs, fVs, oPs, oVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb5500",
   "metadata": {},
   "source": [
    "# DOFramework Example\n",
    "\n",
    "This notebook will demo ```doframework``` on a naive Optimization with Constraint Learning (OCL) algorithm. Ideally, ```doframework``` will be used against a sophisticated OCL algorithm to check its effectiveness. \n",
    "\n",
    "```doframework``` randomly generates optimization problem instances for the OCL algorithm to solve. These optimization problem instances include $(f,\\Omega,D,x^*)$.\n",
    "- $f$ is a piece-wise linear objective target,\n",
    "- $\\Omega$ is a convex polytope defined by affine constraints,\n",
    "- $D$ is a dataset generated for $f$,\n",
    "- $\\mathbf{x}^* = \\arg \\min_{\\Omega}f$.\n",
    "\n",
    "```doframework``` feeds $(\\Omega,D)$ to the user's OCL algorithm. It then collects its predicted optimum to compare against $\\mathbf{x}^*$.\n",
    "\n",
    "This notebook is divided into two parts. In <span style=\"color:blue\">Part I</span> we will define a naive OCL algorithm and test it. Here, we will work with a PWL object, which is the fundamental object ```doframework``` uses to generate constraints and data.\n",
    "\n",
    "Once we have tested our OCL algorithm, we will switch to <span style=\"color:blue\">Part II</span>, where we will demonstrate the use of ```doframework``` on our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70fe60",
   "metadata": {},
   "source": [
    "# Part I\n",
    "\n",
    "*****\n",
    "\n",
    "## -- Objective\n",
    "\n",
    "We will first define a _test_ objective target to use against our naive OCL algorithm. We will define the objective target as a PWL object, similarly to the way ```doframework``` does it (only for more sophisticated PWL functions).\n",
    "\n",
    "The domain of the objective function we'll use will be a ```box```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0570b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = [[-1,1],[-1,1],[-1,1],[-1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938d1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpoints = np.vstack(list(map(np.array, it.product(*box))))\n",
    "fhull = ConvexHull(fpoints,qhull_options='QJ')\n",
    "dim = fpoints.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430afee",
   "metadata": {},
   "source": [
    "Our test function will be affine, determined by coefficients $\\mathbf{a}$ and intercept $b$,\n",
    "$$f(\\mathbf{x}) = \\mathbf{a}^T\\mathbf{x} + b.$$\n",
    "We encode function $f$ by an array $(\\mathbf{a},b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea305c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = np.concatenate([np.ones(dim),np.zeros(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39407f1d",
   "metadata": {},
   "source": [
    "and evaluate $f$ at the vertices of $\\mbox{dom}(f)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e923df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fvals = np.pad(fpoints,[(0,0),(0,1)],constant_values=1) @ ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e2260",
   "metadata": {},
   "source": [
    "## -- Constraints\n",
    "\n",
    "We will now define _test_ constraints as well. The randomly generated constraints we'll use define a convex polytope $\\Omega$ inside $\\mbox{dom}(f)$. \n",
    "\n",
    "More generally, ```doframework``` randomly generates constraints as convex polytopes within its randomly generated PWL functions' domains.\n",
    "\n",
    "We choose a range of coordinate values within which to sample the vertices of $\\Omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72eb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_range = [[-0.5,1],[-1,0.5],[-1,1],[-1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae2f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_vertex_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff9634f",
   "metadata": {},
   "source": [
    "We'll sample vertics for $\\Omega$ within $\\mbox{dom}(f)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9df74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "opoints = np.vstack(\n",
    "    list(\n",
    "        it.islice(\n",
    "            filter(lambda point: in_domain(np.atleast_2d(point), fhull.equations, tol=tol)[0],\n",
    "                box_iterator(omega_range,1)),\n",
    "            omega_vertex_num)\n",
    "    )\n",
    ")\n",
    "\n",
    "ovals = np.pad(opoints,[(0,0),(0,1)],constant_values=1) @ ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b23a13",
   "metadata": {},
   "source": [
    "## -- PWL Object\n",
    "\n",
    "We're now ready to define a PWL object that will serve us to generate data.\n",
    "\n",
    "A PWL object relies on a triangulation of $\\mbox{dom}(f)$ that incorporates $\\Omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "421bcdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fPs, fVs, oPs, oVs = triangulate(fpoints,opoints,fvals,ovals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873b2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = PWL(fPs,fVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd2d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohull = ConvexHull(np.vstack(oPs),qhull_options='QJ')\n",
    "constraints = np.unique(ohull.equations,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a029407",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_value_interval = [np.array(fVs).min(),np.array(fVs).max()]\n",
    "f_value_range = f_value_interval[1]-f_value_interval[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341c7de",
   "metadata": {},
   "source": [
    "We can use the PWL object $f$ to sample points in its domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c185e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = f.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c387f3",
   "metadata": {},
   "source": [
    "or evaluate points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52e1182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.30554661, -0.17269   ,  1.03391789])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.evaluate(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632859c",
   "metadata": {},
   "source": [
    "## -- Ground Truth\n",
    "\n",
    "Since we have a triangulation of $f$ and $\\Omega$, we also have immediate knowledge of the ground truth. We will later compare it to our naive OCL algorithm's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8ed6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmin = np.argmin(oVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31aa42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = argmin % oVs.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93286523",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(argmin/oVs.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19c295d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_true = oPs[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "144d0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_true_val = f.evaluate(np.atleast_2d(opt_true))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b727caa",
   "metadata": {},
   "source": [
    "## -- Data\n",
    "\n",
    "We'll now generate data from the test objective target $f$. The data we'll sample will be a Gaussian mix in $\\mbox{dom}(f)$. \n",
    "\n",
    "Let's decide how many Gaussians we want in the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b88609",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_num = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ea6c4",
   "metadata": {},
   "source": [
    "and how much noise to add to functions values in relative terms (```noise=0.05``` means $5\\%$ of $f$ value range in $\\mbox{dom}(f)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb4a1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194728b",
   "metadata": {},
   "source": [
    "We'll sample some means for the Gaussians in the mix from $\\mbox{dom}(f)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76c948a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = f.sample(mean_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9297899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [s for s in samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2267b8a8",
   "metadata": {},
   "source": [
    "and sample some non-spherical covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3c4dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "covs = [np.diag(uniform.rvs(f_value_interval[0],f_value_range,dim)**2)*np.eye(dim) for _ in range(mean_num)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f872ca3",
   "metadata": {},
   "source": [
    "We'll also sample ```weights``` for the Gaussians in the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ed58cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = sample_standard_simplex(mean_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c845dc",
   "metadata": {},
   "source": [
    "We'll decide on the number of data points $N$ to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bff16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 750"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12847e06",
   "metadata": {},
   "source": [
    "and finally get some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "215be556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 17:15:35,907\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "D = sampler(f, N, weights, noise*(f_value_range), mean=means, cov=covs, num_cpus=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28840f47",
   "metadata": {},
   "source": [
    "We'll make sure all data points are indeed in $\\mbox{dom}(f)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4ab9d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(f.isin(D[:,:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed46fa",
   "metadata": {},
   "source": [
    "## -- Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb6799",
   "metadata": {},
   "source": [
    "Let's build a simple model class for the predict component of our OCL algorithm.\n",
    "\n",
    "There is only _one_ requirement on the model class instance: it should have a ``predict`` method that accepts and returns ``np.array``'s.\n",
    "\n",
    "The rest is up to us. We can add any attribute like. It will be added to the solution file generated by ``doframework``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36bc427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class predictionModel:\n",
    "    '''\n",
    "    Class for the prediction model of an OCL algorithm.\n",
    "    '''\n",
    "        \n",
    "    model = LinearRegression()\n",
    "    data: InitVar[np.array] = None\n",
    "    r2_score: float = field(init=False)\n",
    "        \n",
    "    def __post_init__(self,data):\n",
    "        if data is not None:\n",
    "            data_nonan = data[~np.any(np.isnan(data),axis=1)]\n",
    "            self.model.fit(data_nonan[:,:-1], data_nonan[:,-1])\n",
    "            self.r2_score = self.model.score(data_nonan[:,:-1], data_nonan[:,-1])\n",
    "\n",
    "    def predict(self, x: np.array) -> np.array:\n",
    "        return self.model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd48e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predictionModel(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8012c7",
   "metadata": {},
   "source": [
    "## -- Solver\n",
    "\n",
    "The solver class will be responsible for the optimization part of the OCL algorithm.\n",
    "\n",
    "This particular solver class is designed to work with a simple linear regressor. It uses the [PuLP solver](https://coin-or.github.io/pulp/# \"PuLP\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37f214cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e513a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class optimizationModel:\n",
    "    '''\n",
    "    Class for the solver of an OCL algorithm.\n",
    "    '''\n",
    "\n",
    "    predict: InitVar[Any]\n",
    "    objective_target: np.array = field(init=False)\n",
    "        \n",
    "    def __post_init__(self,predict):\n",
    "        self.objective_target = np.concatenate((predict.model.coef_.reshape(-1,1), \n",
    "                                                predict.model.intercept_.reshape(-1,1)))\n",
    "        self.objective_target = self.objective_target.flatten()\n",
    "\n",
    "    def optimize(self,constraints,is_minimum) -> np.array:\n",
    "        \n",
    "        n = self.objective_target.shape[-1]\n",
    "        variables = [*range(n)]\n",
    "        x = LpVariable.dicts(\"x\", variables)\n",
    "\n",
    "        prob = LpProblem(\"Optimization\",LpMinimize) if is_minimum else LpProblem(\"Optimization\",LpMaximize)\n",
    "        prob += lpSum([self.objective_target[i] * x[i] for i in variables]), \"Objective Target\"\n",
    "        prob += x[n-1] == 1, \"Intercept\"\n",
    "\n",
    "        for k, eqn in enumerate(constraints):\n",
    "            prob += (\n",
    "                pulp.lpSum([eqn[i]*x[i] for i in variables]) <= 0,\n",
    "                f\"constraint_from_{k}th_facet\",\n",
    "            )\n",
    "        prob.solve(PULP_CBC_CMD(msg=0)) # disable logs with msg=0\n",
    "\n",
    "        return np.array([v.varValue for v in prob.variables()],dtype=np.float32)[:-1] # remove intercept coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa7542b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = optimizationModel(model)\n",
    "opt_pred = solver.optimize(constraints,is_minimum=True)\n",
    "opt_pred_val = model.predict(np.atleast_2d(opt_pred))[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d605964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True optimum: [-0.13544908 -0.6496841  -0.56701784 -0.10700867]\n",
      "Predicted optimum: [ 0.5345709  -0.9123484  -0.19548994 -0.5805167 ]\n",
      "True optimal values: -1.459159697730423\n",
      "Predicted optimal value: -0.5752061738654781\n"
     ]
    }
   ],
   "source": [
    "print(f'True optimum: {opt_true}\\nPredicted optimum: {opt_pred}\\nTrue optimal values: {opt_true_val}\\nPredicted optimal value: {opt_pred_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120e741",
   "metadata": {},
   "source": [
    "# Part II\n",
    "\n",
    "****\n",
    "\n",
    "## -- OCL Algorithm\n",
    "\n",
    "Now that we tested our naive OCL scheme, we can package it as a function that ```doframework``` can integrate into its flow.\n",
    "\n",
    "Our function should accept ``data`` and ``constraints`` as input and produce an ``optimum`` with its predicted ``value`` as well as a ``model`` that was used in the predict phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d46d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocl(data: np.array, constraints: np.array, **kwargs):\n",
    "\n",
    "    is_minimum = kwargs['is_minimum'] if 'is_minimum' in kwargs else True\n",
    "                \n",
    "    try:\n",
    "\n",
    "        data_feasible = data[np.all(np.pad(data[:,:-1],((0,0),(0,1)),constant_values=1) @ constraints.T <= 0, axis=1)]\n",
    "        model = predictionModel(data_feasible)\n",
    "        solver = optimizationModel(model)\n",
    "        optimum = solver.optimize(constraints,is_minimum)\n",
    "        predicted_value = model.predict(np.atleast_2d(optimum))[0]    \n",
    "\n",
    "    except Exception as e:\n",
    "        print('Exception: Prediction optimization failed.')\n",
    "        print(e)\n",
    "        return None, None, None\n",
    "\n",
    "    else:\n",
    "\n",
    "        return optimum, predicted_value, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9952dfd",
   "metadata": {},
   "source": [
    "To integrate our simple algorithm into ```doframework```, we need to **resolve** it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5af09629",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dof.resolve\n",
    "def ocl_resolved(data: np.array, constraints: np.array, **kwargs):\n",
    "    return ocl(data, constraints, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f636898",
   "metadata": {},
   "source": [
    "## -- Configs\n",
    "\n",
    "`doframework` relies on a configs yaml to enable its interaction with storage. \n",
    "\n",
    "Storage can be S3 buckets (AWS / IBM Cloud) or a local file system. \n",
    "\n",
    "Here, we will rely on local storage. We already uploaded `sim_configs.yaml` to this `ocl_lab` directory. Here is what it looks like:\n",
    "```\n",
    "local:\n",
    "  buckets: \n",
    "    inputs: '../../data/dof-simulation/inputs'\n",
    "    inputs_dest: '../../data/dof-simulation/inputs-dest'\n",
    "    objectives: '../../data/dof-simulation/objectives'\n",
    "    objectives_dest: '../../data/dof-simulation/objectives-dest'\n",
    "    data: '../../data/dof-simulation/data'\n",
    "    data_dest: '../../data/dof-simulation/data-dest'\n",
    "    solutions: '../../data/dof-simulation/solutions'\n",
    "```\n",
    "\n",
    "Each `doframework` simulation product type has a _source_ bucket and a _target_ bucket underscored with `_dest`. At the end of a `doframework` run, you will find all simulation products in their `_dest` folders, except for algorithm solution files which will be under the `solutions` bucket.\n",
    "\n",
    "We must make sure the bucket nanes we provide are **DISTINCT**. You will find all accepted configuration formats under [`doframework/configs`](https://github.com/IBM/doframework/tree/main/configs).\n",
    "\n",
    "To prepare for a `doframework` run, we will clean the buckets and resolve the relative paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69b5c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "configs_file = 'sim_configs.yaml'\n",
    "configs_path = os.path.join(root,configs_file)\n",
    "\n",
    "sim_configs = get_configs(configs_path)\n",
    "storage = Storage(sim_configs)\n",
    "buckets = storage.buckets()\n",
    "assert len(buckets)>0, 'Buckets retrieval failed!'\n",
    "\n",
    "configs_resolved = {'local': {'buckets': {}}}\n",
    "for name, bucket in buckets.items():    \n",
    "    configs_resolved['local']['buckets'][name] = str(Path(bucket).resolve())\n",
    "    for file in os.listdir(bucket):\n",
    "        file_path = os.path.join(bucket, file)\n",
    "        os.unlink(file_path)\n",
    "with open(configs_path, \"w\") as path: \n",
    "    yaml.dump(configs_resolved, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97329067",
   "metadata": {},
   "source": [
    "## -- Inputs\n",
    "\n",
    "To run `doframework`, we need input json files with meta data for `doframework` to generate objectives, constraints, and datasets. \n",
    "\n",
    "Here is an example of `input_basic.json` uploaded to `ocl_lab/notebooks/DOFramework`:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"f\": {\n",
    "        \"vertices\": {\n",
    "            \"num\": 20,\n",
    "            \"range\": [[0.0,10.0],[0.0,10.0],[0.0,10.0],[0.0,10.0],[0.0,10.0]]\n",
    "        },\n",
    "        \"values\": {\n",
    "            \"range\": [-10.0,10.0]\n",
    "        }\n",
    "    },\n",
    "    \"omega\": {\n",
    "        \"ratio\": 0.6\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"N\": 1000,\n",
    "        \"noise\": 0.01,\n",
    "        \"policy_num\": 3,\n",
    "        \"scale\": 0.7\n",
    "    },\n",
    "    \"input_file_name\": \"input_basic.json\"\n",
    "}\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e42b37",
   "metadata": {},
   "source": [
    "Let's copy `input_basic.json` to the `inputs` bucket specified in `sim_configs.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fcfb7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/dof-simulation/inputs/input_basic.json'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'input_basic.json'\n",
    "input_path = os.path.join(buckets['inputs'],input_file)\n",
    "\n",
    "shutil.copyfile(input_file, input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ab5ea",
   "metadata": {},
   "source": [
    "This input file tells `doframework` to generate continuous piece-wise linear functions supported in `f[vertices][range]` $\\subseteq \\mathbb{R}^5$ with `f[vertices][num]` vertices (more vertices -> more complex functions). $f(\\mathbf{x})$ values will be bounded in `f[values][range]`. \n",
    "\n",
    "This input file tells ```doframework``` to generate a polytope of constraints $\\Omega$ that covers at least ```omega[ratio]``` of $\\mbox{dom}(f)$. It tells `doframework` to generate `data[N]` points in each dataset as a Gaussian mix with `data[policy_num]` centers. The maximum length scale for each Gaussian will be at most `data[scale]` of $\\mbox{dom}(f)$ diameter. Noise will be introduced to $f$ values with STD  of `data[noise]`$\\cdot$`f[values][range]`.\n",
    "You will find accepted input formats under [`doframework/inputs`](https://github.com/IBM/doframework/tree/main/inputs). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc20e9",
   "metadata": {},
   "source": [
    "## -- Run\n",
    "\n",
    "We are finally ready to run ```doframework```. It will generate the specified number of objective targets and datasets per objective target, then run the dataset together with generated constraints against our ```ocl_resolved```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38405188",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives_num = 3\n",
    "feasibility_regions_num = 1\n",
    "datasets_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f7bd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_objectives_num = objectives_num\n",
    "expected_datasets_num = expected_objectives_num*datasets_num\n",
    "expected_solutions_num = expected_datasets_num*feasibility_regions_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e353b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 17:15:49,157\tINFO worker.py:1370 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(root) INFO ... Running simulation with args objectives=3 datasets=3 feasibility_regions=1 distribute=True run_mode=local logger=True\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92030)\u001b[0m Exec command =>  /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/bin/python3.8 /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/harness.py kamel local run --property quarkus.http.port=65493 -d camel:camel-quarkus-microprofile-health /Users/oritd/Workspace/ocl_lab/notebooks/DOFramework/inputs-file-sink.yaml\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92030)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92030)\u001b[0m Integration inputs-file-sink is ready.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92030)\u001b[0m Exec command =>  /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/bin/python3.8 /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/harness.py kamel local run /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/FileQueue.java /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/FileQueueName.java -d mvn:com.googlecode.json-simple:json-simple:1.1.1 --property quarkus.http.port=55707 -d camel:camel-quarkus-microprofile-health /Users/oritd/Workspace/ocl_lab/notebooks/DOFramework/inputs-file-source.yaml\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92030)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92030)\u001b[0m Integration inputs-file-source is ready.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92079)\u001b[0m Exec command =>  /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/bin/python3.8 /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/harness.py kamel local run --property quarkus.http.port=56799 -d camel:camel-quarkus-microprofile-health /Users/oritd/Workspace/ocl_lab/notebooks/DOFramework/objectives-file-sink.yaml\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (input) INFO ... Process successfully extracted event of type json.\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (input) INFO ... Process working on event input_basic.json.\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (input) INFO ... Process working on event input_basic.json will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/objectives.\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (input) INFO ... Process will write 3 products of event input_basic.json to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/objectives.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92079)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92079)\u001b[0m Integration objectives-file-sink is ready.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92079)\u001b[0m Exec command =>  /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/bin/python3.8 /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/harness.py kamel local run /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/FileQueue.java /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/FileQueueName.java -d mvn:com.googlecode.json-simple:json-simple:1.1.1 --property quarkus.http.port=58003 -d camel:camel-quarkus-microprofile-health /Users/oritd/Workspace/ocl_lab/notebooks/DOFramework/objectives-file-source.yaml\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92079)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92079)\u001b[0m Integration objectives-file-source is ready.\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (objective) INFO ... Process successfully extracted event of type json.\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (objective) INFO ... Process working on event objective_3sc23ilr.json.\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (objective) INFO ... Process working on event objective_3sc23ilr.json will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/data.\n",
      "\u001b[2m\u001b[36m(inner pid=92082)\u001b[0m (objective) INFO ... Process will write 3 products of event objective_3sc23ilr.json to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/data.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92140)\u001b[0m Exec command =>  /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/bin/python3.8 /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/harness.py kamel local run --property quarkus.http.port=55733 -d camel:camel-quarkus-microprofile-health /Users/oritd/Workspace/ocl_lab/notebooks/DOFramework/data-file-sink.yaml\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (objective) INFO ... Process successfully extracted event of type json.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (objective) INFO ... Process working on event objective_vhvqfrp0.json.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (objective) INFO ... Process working on event objective_vhvqfrp0.json will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/data.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (objective) INFO ... Process will write 3 products of event objective_vhvqfrp0.json to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/data.\n",
      "\u001b[2m\u001b[36m(inner pid=92143)\u001b[0m (objective) INFO ... Process successfully extracted event of type json.\n",
      "\u001b[2m\u001b[36m(inner pid=92143)\u001b[0m (objective) INFO ... Process working on event objective_ouyqc44o.json.\n",
      "\u001b[2m\u001b[36m(inner pid=92143)\u001b[0m (objective) INFO ... Process working on event objective_ouyqc44o.json will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/data.\n",
      "\u001b[2m\u001b[36m(inner pid=92143)\u001b[0m (objective) INFO ... Process will write 3 products of event objective_ouyqc44o.json to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 17:17:10,023\tWARNING worker.py:1851 -- WARNING: 18 PYTHON worker processes have been started on node: ccf397e929cfeed45c49b4a0291a453a802f08b0a764090339124077 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "2023-01-09 17:17:11,737\tWARNING worker.py:1851 -- WARNING: 20 PYTHON worker processes have been started on node: ccf397e929cfeed45c49b4a0291a453a802f08b0a764090339124077 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "2023-01-09 17:17:23,382\tWARNING worker.py:1851 -- WARNING: 24 PYTHON worker processes have been started on node: ccf397e929cfeed45c49b4a0291a453a802f08b0a764090339124077 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(StreamActor pid=92140)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92140)\u001b[0m Integration data-file-sink is ready.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92140)\u001b[0m Exec command =>  /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/bin/python3.8 /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/harness.py kamel local run /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/FileQueue.java /Users/oritd/.pyenv/versions/3.8.0/envs/ocl/lib/python3.8/site-packages/rayvens/core/FileQueueName.java -d mvn:com.googlecode.json-simple:json-simple:1.1.1 --property quarkus.http.port=51064 -d camel:camel-quarkus-microprofile-health /Users/oritd/Workspace/ocl_lab/notebooks/DOFramework/data-file-source.yaml\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92140)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
      "\u001b[2m\u001b[36m(StreamActor pid=92140)\u001b[0m Integration data-file-source is ready.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_ouyqc44o_p47pt5ay.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_ouyqc44o_p47pt5ay.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process will write 1 products of event data_ouyqc44o_p47pt5ay.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_vhvqfrp0_v76rv2jf.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_vhvqfrp0_v76rv2jf.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process will write 1 products of event data_vhvqfrp0_v76rv2jf.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_3sc23ilr_kvzm5gr2.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_3sc23ilr_kvzm5gr2.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process will write 1 products of event data_3sc23ilr_kvzm5gr2.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_3sc23ilr_qzj5l4g1.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_3sc23ilr_qzj5l4g1.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process will write 1 products of event data_3sc23ilr_qzj5l4g1.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_vhvqfrp0_470cpboi.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_vhvqfrp0_470cpboi.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process will write 1 products of event data_vhvqfrp0_470cpboi.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_ouyqc44o_uozdnk3m.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process working on event data_ouyqc44o_uozdnk3m.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92144)\u001b[0m (data) INFO ... Process will write 1 products of event data_ouyqc44o_uozdnk3m.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92260)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92260)\u001b[0m (data) INFO ... Process working on event data_vhvqfrp0_t56xjtd3.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92260)\u001b[0m (data) INFO ... Process working on event data_vhvqfrp0_t56xjtd3.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92260)\u001b[0m (data) INFO ... Process will write 1 products of event data_vhvqfrp0_t56xjtd3.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92261)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92261)\u001b[0m (data) INFO ... Process working on event data_3sc23ilr_aymuz1vp.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92261)\u001b[0m (data) INFO ... Process working on event data_3sc23ilr_aymuz1vp.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92261)\u001b[0m (data) INFO ... Process will write 1 products of event data_3sc23ilr_aymuz1vp.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92262)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92262)\u001b[0m (data) INFO ... Process working on event data_ouyqc44o_85z6qzs3.csv.\n",
      "\u001b[2m\u001b[36m(inner pid=92262)\u001b[0m (data) INFO ... Process working on event data_ouyqc44o_85z6qzs3.csv will write to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n",
      "\u001b[2m\u001b[36m(inner pid=92262)\u001b[0m (data) INFO ... Process will write 1 products of event data_ouyqc44o_85z6qzs3.csv to bucket /Users/oritd/Workspace/ocl_lab/data/dof-simulation/solutions.\n"
     ]
    }
   ],
   "source": [
    "dof.run(\n",
    "    ocl_resolved, configs_path, \n",
    "    objectives=objectives_num, \n",
    "    datasets=datasets_num, \n",
    "    feasibility_regions=feasibility_regions_num, \n",
    "    after_idle_for=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e18734fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 objectives out of expected 3.\n",
      "Generated 9 datasets out of expected 9.\n",
      "Generated 9 solutions out of expected 9.\n"
     ]
    }
   ],
   "source": [
    "num_inputs = storage.count(buckets['inputs'],'json')+storage.count(buckets['inputs_dest'],'json')\n",
    "num_objectives = storage.count(buckets['objectives'],'json')+storage.count(buckets['objectives_dest'],'json')\n",
    "num_datasets = storage.count(buckets['data'],'csv')+storage.count(buckets['data_dest'],'csv')\n",
    "num_solutions = storage.count(buckets['solutions'],'json')\n",
    "\n",
    "print(f'Generated {num_objectives} objectives out of expected {expected_objectives_num}.')\n",
    "print(f'Generated {num_datasets} datasets out of expected {expected_datasets_num}.')\n",
    "print(f'Generated {num_solutions} solutions out of expected {expected_solutions_num}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
