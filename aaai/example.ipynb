{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ordavidov/ocl_lab/blob/aaai/aaai/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drive Mount\n",
        "\n",
        "******\n",
        "\n",
        "We need to allow the mounting of data. Press Allow when prompted. "
      ],
      "metadata": {
        "id": "6MeB5Bza2hh_"
      },
      "id": "6MeB5Bza2hh_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mva-gAsP09Fp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29391f80-002a-4cc4-aee1-08d028152c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Mva-gAsP09Fp"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/ocl_lab/notebooks/DOFramework"
      ],
      "metadata": {
        "id": "svXbqbY6_d6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd8d4f5-3988-4885-a4a7-7794a7494d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/ocl_lab/notebooks/DOFramework'\n",
            "/content/drive/MyDrive/ocl_lab/notebooks/DOFramework\n"
          ]
        }
      ],
      "id": "svXbqbY6_d6K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOFramework Setup\n",
        "\n",
        "*****\n",
        "\n",
        "We begin by installing the Python package [`doframework`](https://github.com/IBM/doframework). If you are getting errors, restart the runtime and run this cell again (the errors are due to mismatches between Google Colab built-in environment packages and `doframework` requirements that cannot be automatically resolved)."
      ],
      "metadata": {
        "id": "dHNPlukQIOiZ"
      },
      "id": "dHNPlukQIOiZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iCJwvFRsdi3"
      },
      "outputs": [],
      "source": [
        "%pip install doframework"
      ],
      "id": "8iCJwvFRsdi3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb13acad"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field, InitVar\n",
        "from typing import Any\n",
        "import itertools as it\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial import ConvexHull\n",
        "from scipy.stats import uniform\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from doframework.core.pwl import PWL\n",
        "from doframework.core.sampler import D_sampler as sampler\n",
        "from doframework.core.triangulation import box_iterator\n",
        "from doframework.core.hit_and_run import in_domain\n",
        "from doframework.core.utils import sample_standard_simplex, incidence\n",
        "from doframework.core.storage import Storage\n",
        "from doframework.core.inputs import get_configs\n",
        "\n",
        "tol = 1e-8 # tolerance to near 0"
      ],
      "id": "fb13acad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`doframework` relies on [`rayvens`](https://github.com/project-codeflare/rayvens) for event streaming over [`camel`](https://github.com/apache/camel-k/releases?page=3) and on the event distribution framework [`ray`](https://www.ray.io/). To use the `camel` framework, we need to install it together with [JDK](https://www.oracle.com/java/technologies/downloads/) and [`maven`](https://maven.apache.org/)."
      ],
      "metadata": {
        "id": "vl0xfWcaKRIv"
      },
      "id": "vl0xfWcaKRIv"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/apache/camel-k/releases/download/v1.5.1/camel-k-client-1.5.1-linux-64bit.tar.gz\n",
        "!tar zxvf camel-k-client-1.5.1-linux-64bit.tar.gz\n",
        "!cp ./kamel /usr/local/bin\n",
        "!kamel version\n",
        "\n",
        "def install_java():\n",
        "\n",
        "  !apt update\n",
        "  !apt-get install -y openjdk-11-jdk-headless -qq\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "  !apt-get install -y maven \n",
        "  !java -version\n",
        "  !mvn -version\n",
        "  \n",
        "install_java()"
      ],
      "metadata": {
        "id": "L9cNYGWZU5v9"
      },
      "execution_count": null,
      "outputs": [],
      "id": "L9cNYGWZU5v9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d490dbde"
      },
      "outputs": [],
      "source": [
        "def triangulate(fpoints: np.array, opoints: np.array, fvals: np.array, ovals: np.array):\n",
        "    \n",
        "    assert all([fpoints.shape[0]==fvals.flatten().size,opoints.shape[0]==ovals.flatten().size]), 'Length of values array should match the number of row vectors.'\n",
        "\n",
        "    m = fpoints.min()\n",
        "    M = fpoints.max()\n",
        "\n",
        "    olift = np.hstack([opoints,(np.random.rand(opoints.shape[0])*(M-m)+m)[:,None]])\n",
        "    flift = np.hstack([fpoints,(np.random.rand(fpoints.shape[0])*(M-m)+11*(M-m)+m)[:,None]]) \n",
        "\n",
        "    P = np.vstack([opoints,fpoints])\n",
        "    _, unique_indices = np.unique(P, axis=0, return_index=True) \n",
        "    Plift = np.vstack([olift,flift])[unique_indices]\n",
        "\n",
        "    view_point = np.concatenate([P.mean(axis=0),np.array([m-1000*(M-m)])]) \n",
        "    envelope = ConvexHull(np.vstack([np.atleast_2d(view_point),Plift]),qhull_options='QG0')\n",
        "    good_indices = envelope.simplices[envelope.good]\n",
        "    fPs = envelope.points[good_indices,:][:,:,:-1]\n",
        "\n",
        "    V = np.concatenate([ovals,fvals])[unique_indices]\n",
        "    fVs = V[:,None][good_indices-1].reshape(*good_indices.shape) # view point at index 0\n",
        "\n",
        "    oin = [np.all(incidence(opoints,fp).any(axis=0)) for fp in fPs]\n",
        "    oPs = fPs[oin]\n",
        "    oVs = fVs[oin]\n",
        "\n",
        "    if oPs.size == 0: # when fail to catch omega lower envelope\n",
        "        oPs, oVs = fPs, fVs\n",
        "\n",
        "    return fPs, fVs, oPs, oVs"
      ],
      "id": "d490dbde"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ddb5500"
      },
      "source": [
        "# DOFramework Example\n",
        "\n",
        "*****\n",
        "\n",
        "This notebook will demo ```doframework``` on a naive DO model learner. Ideally, ```doframework``` will be used against a more sophisticated DO model learner, such as [OptiCL](https://github.com/hwiberg/OptiCL), to establish its solution quality profile. \n",
        "\n",
        "`doframework` randomly generates optimization problem instances $(f,\\Omega,D,\\mathbf{x}^*)$ for the user's DO model learner to solve. These optimization problem instances include:\n",
        "* $f: \\mathbb{R}^d → \\mathbb{R}$ a continuous piece-wise linear objective.\n",
        "* $\\Omega ⊆ \\mathbb{R}^d$ a feasibility region as a bounded convex $d$-polytope.\n",
        "* $D = (X,y)$ data associated with $f$ so that $X ⊆ \\mbox{dom}(f)$ and $y = f(\\mathbf{x}) + ϵ$, $ϵ \\sim \\mathcal{N}(0,σ^2)$.\n",
        "* $\\mathbf{x}^* = \\arg \\min_{\\mathbf{x} \\in Ω} f(\\mathbf{x})$ the ground-truth optimum.\n",
        "\n",
        "`doframework` feeds $(\\Omega,D)$ to the user's DO model learner. It then collects its predicted optimum $\\hat{\\mathbf{x}}$ to compare against $\\mathbf{x}$.\n",
        "\n",
        "This notebook is divided into two parts:\n",
        "\n",
        "<font color=green>Part I</font>: We define a naive DO model learner and test it. Here, we work with a PWL object, which is the fundamental object ```doframework``` uses to generate constraints and data.\n",
        "\n",
        "<font color=green>Part II</font>: Once we have tested our naive DO model learner, we demonstrate running ```doframework``` against it."
      ],
      "id": "7ddb5500"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd70fe60"
      },
      "source": [
        "# Part I\n",
        "\n",
        "*****\n",
        "\n"
      ],
      "id": "bd70fe60"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -- Objective\n",
        "\n",
        "We first define a _test_ objective target to use against our naive DO model learner. We define the objective target as a PWL object, similarly to the way ```doframework``` does it (only for more sophisticated PWL functions).\n",
        "\n",
        "The domain of the objective function we'll use will be a ```box```."
      ],
      "metadata": {
        "id": "fnAscQ9sjWhx"
      },
      "id": "fnAscQ9sjWhx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0570b693"
      },
      "outputs": [],
      "source": [
        "box = [[-1,1],[-1,1],[-1,1],[-1,1]]"
      ],
      "id": "0570b693"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "938d1a23"
      },
      "outputs": [],
      "source": [
        "fpoints = np.vstack(list(map(np.array, it.product(*box))))\n",
        "fhull = ConvexHull(fpoints,qhull_options='QJ')\n",
        "dim = fpoints.shape[-1]"
      ],
      "id": "938d1a23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d430afee"
      },
      "source": [
        "Our test function will be affine, determined by coefficients $\\mathbf{a}$ and intercept $b$,\n",
        "$$f(\\mathbf{x}) = \\mathbf{a}^T\\mathbf{x} + b.$$\n",
        "We encode function $f$ by an array $(\\mathbf{a},b)$."
      ],
      "id": "d430afee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ea305c6"
      },
      "outputs": [],
      "source": [
        "ab = np.concatenate([np.ones(dim),np.zeros(1)])"
      ],
      "id": "1ea305c6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39407f1d"
      },
      "source": [
        "and evaluate $f$ at the vertices of $\\mbox{dom}(f)$."
      ],
      "id": "39407f1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e923df2"
      },
      "outputs": [],
      "source": [
        "fvals = np.pad(fpoints,[(0,0),(0,1)],constant_values=1) @ ab"
      ],
      "id": "8e923df2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221e2260"
      },
      "source": [
        "## -- Constraints\n",
        "\n",
        "We will now define _test_ constraints as well. The randomly generated constraints we'll use define a convex polytope $\\Omega$ inside $\\mbox{dom}(f)$. \n",
        "\n",
        "More generally, ```doframework``` randomly generates constraints as convex polytopes within its randomly generated PWL functions' domains.\n",
        "\n",
        "We choose a range of coordinate values within which to sample the vertices of $\\Omega$."
      ],
      "id": "221e2260"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a72eb22e"
      },
      "outputs": [],
      "source": [
        "omega_range = [[-0.5,1],[-1,0.5],[-1,1],[-1,1]]"
      ],
      "id": "a72eb22e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eae2f001"
      },
      "outputs": [],
      "source": [
        "omega_vertex_num = 10"
      ],
      "id": "eae2f001"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dff9634f"
      },
      "source": [
        "We'll sample vertics for $\\Omega$ within $\\mbox{dom}(f)$."
      ],
      "id": "dff9634f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9df74df"
      },
      "outputs": [],
      "source": [
        "opoints = np.vstack(\n",
        "    list(\n",
        "        it.islice(\n",
        "            filter(lambda point: in_domain(np.atleast_2d(point), fhull.equations, tol=tol)[0],\n",
        "                box_iterator(omega_range,1)),\n",
        "            omega_vertex_num)\n",
        "    )\n",
        ")\n",
        "\n",
        "ovals = np.pad(opoints,[(0,0),(0,1)],constant_values=1) @ ab"
      ],
      "id": "d9df74df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1b23a13"
      },
      "source": [
        "## -- PWL Object\n",
        "\n",
        "We're now ready to define a PWL object that will serve us to generate data.\n",
        "\n",
        "A PWL object relies on a triangulation of $\\mbox{dom}(f)$ that incorporates $\\Omega$."
      ],
      "id": "c1b23a13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "421bcdd8"
      },
      "outputs": [],
      "source": [
        "fPs, fVs, oPs, oVs = triangulate(fpoints,opoints,fvals,ovals)"
      ],
      "id": "421bcdd8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "873b2ef8"
      },
      "outputs": [],
      "source": [
        "f = PWL(fPs,fVs)"
      ],
      "id": "873b2ef8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bd2d762"
      },
      "outputs": [],
      "source": [
        "ohull = ConvexHull(np.vstack(oPs),qhull_options='QJ')\n",
        "constraints = np.unique(ohull.equations,axis=0)"
      ],
      "id": "6bd2d762"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a029407"
      },
      "outputs": [],
      "source": [
        "f_value_interval = [np.array(fVs).min(),np.array(fVs).max()]\n",
        "f_value_range = f_value_interval[1]-f_value_interval[0]"
      ],
      "id": "3a029407"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d341c7de"
      },
      "source": [
        "We can use the PWL object $f$ to sample points in its domain."
      ],
      "id": "d341c7de"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c185e381"
      },
      "outputs": [],
      "source": [
        "xs = f.sample(3)"
      ],
      "id": "c185e381"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80c387f3"
      },
      "source": [
        "or evaluate points"
      ],
      "id": "80c387f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52e1182c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a63c66e-995f-4f5f-b4ca-2b79d22a8b2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.77111284,  2.2665267 , -1.98071267])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "f.evaluate(xs)"
      ],
      "id": "52e1182c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a632859c"
      },
      "source": [
        "## -- Ground Truth\n",
        "\n",
        "Since we have a triangulation of $f$ and $\\Omega$, we also have immediate knowledge of the ground truth. We will later compare it to our naive DO model learner's results."
      ],
      "id": "a632859c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df8ed6a3"
      },
      "outputs": [],
      "source": [
        "argmin = np.argmin(oVs)"
      ],
      "id": "df8ed6a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31aa42bb"
      },
      "outputs": [],
      "source": [
        "j = argmin % oVs.shape[-1]"
      ],
      "id": "31aa42bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93286523"
      },
      "outputs": [],
      "source": [
        "i = int(argmin/oVs.shape[-1])"
      ],
      "id": "93286523"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19c295d7"
      },
      "outputs": [],
      "source": [
        "opt_true = oPs[i][j]"
      ],
      "id": "19c295d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "144d0ed1"
      },
      "outputs": [],
      "source": [
        "opt_true_val = f.evaluate(np.atleast_2d(opt_true))[0]"
      ],
      "id": "144d0ed1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b727caa"
      },
      "source": [
        "## -- Data\n",
        "\n",
        "We'll now generate data from the test objective target $f$. The data we'll sample will be a Gaussian mix in $\\mbox{dom}(f)$. \n",
        "\n",
        "Let's decide how many Gaussians we want in the mix."
      ],
      "id": "3b727caa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65b88609"
      },
      "outputs": [],
      "source": [
        "mean_num = 3"
      ],
      "id": "65b88609"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df3ea6c4"
      },
      "source": [
        "and how much noise to add to functions values in relative terms (```noise=0.05``` means $5\\%$ of $f$ value range in $\\mbox{dom}(f)$)."
      ],
      "id": "df3ea6c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb4a1602"
      },
      "outputs": [],
      "source": [
        "noise = 0.05"
      ],
      "id": "bb4a1602"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8194728b"
      },
      "source": [
        "We'll sample some means for the Gaussians in the mix from $\\mbox{dom}(f)$."
      ],
      "id": "8194728b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76c948a9"
      },
      "outputs": [],
      "source": [
        "samples = f.sample(mean_num)"
      ],
      "id": "76c948a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9297899c"
      },
      "outputs": [],
      "source": [
        "means = [s for s in samples]"
      ],
      "id": "9297899c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2267b8a8"
      },
      "source": [
        "and sample some non-spherical covariance matrices."
      ],
      "id": "2267b8a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3c4dd39"
      },
      "outputs": [],
      "source": [
        "covs = [np.diag(uniform.rvs(f_value_interval[0],f_value_range,dim)**2)*np.eye(dim) for _ in range(mean_num)]"
      ],
      "id": "d3c4dd39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f872ca3"
      },
      "source": [
        "We'll also sample ```weights``` for the Gaussians in the mix."
      ],
      "id": "4f872ca3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ed58cdc"
      },
      "outputs": [],
      "source": [
        "weights = sample_standard_simplex(mean_num)"
      ],
      "id": "4ed58cdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82c845dc"
      },
      "source": [
        "We'll decide on the number of data points $N$ to sample."
      ],
      "id": "82c845dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bff16cf"
      },
      "outputs": [],
      "source": [
        "N = 750"
      ],
      "id": "5bff16cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12847e06"
      },
      "source": [
        "and finally get some samples."
      ],
      "id": "12847e06"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "215be556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2fce36-a236-41c0-90d8-3b7ecba1940b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-05 12:29:19,887\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        }
      ],
      "source": [
        "D = sampler(f, N, weights, noise*(f_value_range), mean=means, cov=covs, num_cpus=4)"
      ],
      "id": "215be556"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28840f47"
      },
      "source": [
        "We'll make sure all data points are indeed in $\\mbox{dom}(f)$."
      ],
      "id": "28840f47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4ab9d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef8137c-9cd0-47b9-c3a7-87258120e89f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "np.all(f.isin(D[:,:-1]))"
      ],
      "id": "d4ab9d94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ed46fa"
      },
      "source": [
        "## -- Model"
      ],
      "id": "b9ed46fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2eb6799"
      },
      "source": [
        "Let's build a simple model class for the predict component of our DO model learner.\n",
        "\n",
        "There is only _one_ requirement on the model class instance: it should have a ``predict`` method that accepts and returns ``np.array``'s.\n",
        "\n",
        "The rest is up to us. We can add any attribute we like. It will be added to the solution file generated by ``doframework``."
      ],
      "id": "e2eb6799"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36bc427e"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class predictionModel:\n",
        "    '''\n",
        "    Class for the prediction model of an OCL algorithm.\n",
        "    '''\n",
        "        \n",
        "    model = LinearRegression()\n",
        "    data: InitVar[np.array] = None\n",
        "    r2_score: float = field(init=False)\n",
        "        \n",
        "    def __post_init__(self,data):\n",
        "        if data is not None:\n",
        "            data_nonan = data[~np.any(np.isnan(data),axis=1)]\n",
        "            self.model.fit(data_nonan[:,:-1], data_nonan[:,-1])\n",
        "            self.r2_score = self.model.score(data_nonan[:,:-1], data_nonan[:,-1])\n",
        "\n",
        "    def predict(self, x: np.array) -> np.array:\n",
        "        return self.model.predict(x)\n"
      ],
      "id": "36bc427e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd48e7b5"
      },
      "outputs": [],
      "source": [
        "model = predictionModel(D)"
      ],
      "id": "dd48e7b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8012c7"
      },
      "source": [
        "## -- Solver\n",
        "\n",
        "The solver class will be responsible for the optimization part of the DO model learner.\n",
        "\n",
        "This particular solver class is designed to work with a simple linear regressor. It uses the [PuLP solver](https://coin-or.github.io/pulp/# \"PuLP\")."
      ],
      "id": "bd8012c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37f214cc"
      },
      "outputs": [],
      "source": [
        "from pulp import *"
      ],
      "id": "37f214cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e513a87a"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class optimizationModel:\n",
        "    '''\n",
        "    Class for the solver of an OCL algorithm.\n",
        "    '''\n",
        "\n",
        "    predict: InitVar[Any]\n",
        "    objective_target: np.array = field(init=False)\n",
        "        \n",
        "    def __post_init__(self,predict):\n",
        "        self.objective_target = np.concatenate((predict.model.coef_.reshape(-1,1), \n",
        "                                                predict.model.intercept_.reshape(-1,1)))\n",
        "        self.objective_target = self.objective_target.flatten()\n",
        "\n",
        "    def optimize(self,constraints,is_minimum) -> np.array:\n",
        "        \n",
        "        n = self.objective_target.shape[-1]\n",
        "        variables = [*range(n)]\n",
        "        x = LpVariable.dicts(\"x\", variables)\n",
        "\n",
        "        prob = LpProblem(\"Optimization\",LpMinimize) if is_minimum else LpProblem(\"Optimization\",LpMaximize)\n",
        "        prob += lpSum([self.objective_target[i] * x[i] for i in variables]), \"Objective Target\"\n",
        "        prob += x[n-1] == 1, \"Intercept\"\n",
        "\n",
        "        for k, eqn in enumerate(constraints):\n",
        "            prob += (\n",
        "                pulp.lpSum([eqn[i]*x[i] for i in variables]) <= 0,\n",
        "                f\"constraint_from_{k}th_facet\",\n",
        "            )\n",
        "        prob.solve(PULP_CBC_CMD(msg=0)) # disable logs with msg=0\n",
        "\n",
        "        return np.array([v.varValue for v in prob.variables()],dtype=np.float32)[:-1] # remove intercept coord\n"
      ],
      "id": "e513a87a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa7542b3"
      },
      "outputs": [],
      "source": [
        "solver = optimizationModel(model)\n",
        "opt_pred = solver.optimize(constraints,is_minimum=True)\n",
        "opt_pred_val = model.predict(np.atleast_2d(opt_pred))[0]    "
      ],
      "id": "fa7542b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d605964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f42eae-2b8e-47d8-d41c-0f903923f2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True optimum: [-0.40317202  0.22456282 -0.42764151 -0.94423115]\n",
            "Predicted optimum: [-0.40317202  0.22456282 -0.4276415  -0.94423115]\n",
            "True optimal values: -1.5504818648961487\n",
            "Predicted optimal value: -1.5556271366426784\n"
          ]
        }
      ],
      "source": [
        "print(f'True optimum: {opt_true}\\nPredicted optimum: {opt_pred}\\nTrue optimal values: {opt_true_val}\\nPredicted optimal value: {opt_pred_val}')"
      ],
      "id": "4d605964"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4120e741"
      },
      "source": [
        "# Part II\n",
        "\n",
        "****\n",
        "\n",
        "## -- DO Model Learner\n",
        "\n",
        "Now that we tested our naive DO model learner, we can package it as a function that ```doframework``` can integrate into its flow.\n",
        "\n",
        "Our function should accept ``data`` and ``constraints`` as input and produce an ``optimum`` with its predicted ``value`` as well as a ``model`` with a ``predict`` method."
      ],
      "id": "4120e741"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "506bf769"
      },
      "outputs": [],
      "source": [
        "import doframework as dof"
      ],
      "id": "506bf769"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d46d5c0"
      },
      "outputs": [],
      "source": [
        "def ocl(data: np.array, constraints: np.array, **kwargs):\n",
        "\n",
        "    is_minimum = kwargs['is_minimum'] if 'is_minimum' in kwargs else True\n",
        "                \n",
        "    try:\n",
        "\n",
        "        data_feasible = data[np.all(np.pad(data[:,:-1],((0,0),(0,1)),constant_values=1) @ constraints.T <= 0, axis=1)]\n",
        "        model = predictionModel(data_feasible)\n",
        "        solver = optimizationModel(model)\n",
        "        optimum = solver.optimize(constraints,is_minimum)\n",
        "        predicted_value = model.predict(np.atleast_2d(optimum))[0]    \n",
        "\n",
        "    except Exception as e:\n",
        "      \n",
        "        print('Exception: Prediction optimization failed.')\n",
        "        print(e)\n",
        "        return None, None, None\n",
        "\n",
        "    else:\n",
        "\n",
        "        return optimum, predicted_value, model"
      ],
      "id": "7d46d5c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9952dfd"
      },
      "source": [
        "To integrate our simple DO model learner into ```doframework```, we need to **resolve** it."
      ],
      "id": "f9952dfd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5af09629"
      },
      "outputs": [],
      "source": [
        "@dof.resolve\n",
        "def ocl_resolved(data: np.array, constraints: np.array, **kwargs):\n",
        "    return ocl(data, constraints, **kwargs)"
      ],
      "id": "5af09629"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f636898"
      },
      "source": [
        "## -- Configs\n",
        "\n",
        "`doframework` relies on a configs yaml to enable its interaction with storage. Storage can be S3 buckets (AWS / IBM Cloud) or a local file system. Here, we will rely on local storage. We already uploaded `sim_configs.yaml` to our `ocl_lab` directory. Here is what it looks like:\n",
        "```\n",
        "local:\n",
        "  buckets: \n",
        "    inputs: '../ocl_lab/data/dof-simulation/inputs'\n",
        "    inputs_dest: '../ocl_lab/data/dof-simulation/inputs-dest'\n",
        "    objectives: '../ocl_lab/data/dof-simulation/objectives'\n",
        "    objectives_dest: '../ocl_lab/data/dof-simulation/objectives-dest'\n",
        "    data: '../ocl_lab/data/dof-simulation/data'\n",
        "    data_dest: '../ocl_lab/data/dof-simulation/data-dest'\n",
        "    solutions: '../ocl_lab/data/dof-simulation/solutions'\n",
        "```\n",
        "\n",
        "Each `doframework` simulation product type has a _source_ bucket and a _target_ bucket underscored with `_dest`. At the end of a `doframework` run, you will find all simulation products in their `_dest` folders, except for algorithm solution files which will be under the `solutions` bucket.\n",
        "\n",
        "We must make sure the bucket names we provide are **DISTINCT**. You will find all accepted configuration formats under [`doframework/configs`](https://github.com/IBM/doframework/tree/main/configs). "
      ],
      "id": "5f636898"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69b5c623"
      },
      "outputs": [],
      "source": [
        "root = os.getcwd()\n",
        "configs_file = 'sim_configs.yaml'\n",
        "configs_path = os.path.join(root,configs_file)\n",
        "\n",
        "sim_configs = get_configs(configs_path)\n",
        "storage = Storage(sim_configs)\n",
        "buckets = storage.buckets()\n",
        "assert len(buckets)>0, 'Buckets retrieval failed!'\n",
        "\n",
        "configs_resolved = {'local': {'buckets': {}}}\n",
        "for name, bucket in buckets.items():    \n",
        "    configs_resolved['local']['buckets'][name] = str(Path(bucket).resolve())\n",
        "    for file in os.listdir(bucket):\n",
        "        file_path = os.path.join(bucket, file)\n",
        "        os.unlink(file_path)\n",
        "with open(configs_path, \"w\") as path: \n",
        "    yaml.dump(configs_resolved, path)"
      ],
      "id": "69b5c623"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a5ab5ea"
      },
      "source": [
        "## -- Inputs\n",
        "\n",
        "To run `doframework`, we need input json files with meta data for `doframework` to generate objectives, constraints, and datasets. \n",
        "\n",
        "Here is an example of `input_basic.json` uploaded to `ocl_lab/notebooks/DOFramework`:\n",
        "```\n",
        "{\n",
        "    \"f\": {\n",
        "        \"vertices\": {\n",
        "            \"num\": 20,\n",
        "            \"range\": [[0.0,10.0],[0.0,10.0],[0.0,10.0],[0.0,10.0],[0.0,10.0]]\n",
        "        },\n",
        "        \"values\": {\n",
        "            \"range\": [-10.0,10.0]\n",
        "        }\n",
        "    },\n",
        "    \"omega\": {\n",
        "        \"ratio\": 0.6\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"N\": 1000,\n",
        "        \"noise\": 0.01,\n",
        "        \"policy_num\": 3,\n",
        "        \"scale\": 0.7\n",
        "    },\n",
        "    \"input_file_name\": \"input_basic.json\"\n",
        "}\n",
        "``` \n",
        "\n"
      ],
      "id": "7a5ab5ea"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's copy `input_basic.json` to the `inputs` bucket specified in `sim_configs.yaml`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8XLwyBO8AEgk"
      },
      "id": "8XLwyBO8AEgk"
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'input_basic.json'\n",
        "input_path = os.path.join(buckets['inputs'],input_file)\n",
        "\n",
        "shutil.copyfile(input_file, input_path)"
      ],
      "metadata": {
        "id": "c3-_rzgu_J8s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "272ea7f0-eda9-4978-d5fa-79e6e2b90b6f"
      },
      "id": "c3-_rzgu_J8s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/inputs/input_basic.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This input file tells `doframework` to generate continuous piece-wise linear functions supported in `f[vertices][range]` $\\subseteq \\mathbb{R}^5$ with `f[vertices][num]` vertices (more vertices -> more complex functions). $f(\\mathbf{x})$ values will be bounded in `f[values][range]`. \n",
        "\n",
        "This input file tells ```doframework``` to generate a polytope of constraints $\\Omega$ that covers at least ```omega[ratio]``` of $\\mbox{dom}(f)$. It tells `doframework` to generate `data[N]` points in each dataset as a Gaussian mix with `data[policy_num]` centers. The maximum length scale for each Gaussian will be at most `data[scale]` of $\\mbox{dom}(f)$ diameter. Noise will be introduced to $f$ values with STD  of `data[noise]`$\\cdot$`f[values][range]`.\n",
        "You will find accepted input formats under [`doframework/inputs`](https://github.com/IBM/doframework/tree/main/inputs). "
      ],
      "metadata": {
        "id": "jQN1rNfs_IN0"
      },
      "id": "jQN1rNfs_IN0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aabc20e9"
      },
      "source": [
        "## -- Run\n",
        "\n",
        "We are finally ready to run `doframework`. `doframework` will generate a specified number of objectives, constraints (i.e., feasibility regions), and datasets, and then run them against `ocl_resolved`.\n",
        "\n",
        "The run utility is expected to run roughly $11$ minutes."
      ],
      "id": "aabc20e9"
    },
    {
      "cell_type": "code",
      "source": [
        "objectives_num = 3\n",
        "feasibility_regions_num = 1\n",
        "datasets_num = 3"
      ],
      "metadata": {
        "id": "jBvpufl1VmLJ"
      },
      "id": "jBvpufl1VmLJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expected_objectives_num = objectives_num\n",
        "expected_datasets_num = expected_objectives_num*datasets_num\n",
        "expected_solutions_num = expected_datasets_num*feasibility_regions_num"
      ],
      "metadata": {
        "id": "pXVQF0ndVCJ7"
      },
      "id": "pXVQF0ndVCJ7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e353b5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936cb1ee-930d-487c-a831-e39b1088ad6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-05 12:30:23,070\tINFO worker.py:1370 -- Calling ray.init() again after it has already been called.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(root) INFO ... Running simulation with args objectives=3 datasets=3 feasibility_regions=1 distribute=True run_mode=local logger=True\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15053)\u001b[0m Exec command =>  /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/rayvens/core/harness.py kamel local run --property quarkus.http.port=56367 -d camel:camel-quarkus-microprofile-health /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/notebooks/DOFramework/inputs-file-sink.yaml\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15053)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15053)\u001b[0m Integration inputs-file-sink is ready.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15053)\u001b[0m Exec command =>  /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/rayvens/core/harness.py kamel local run /usr/local/lib/python3.8/dist-packages/rayvens/core/FileQueue.java /usr/local/lib/python3.8/dist-packages/rayvens/core/FileQueueName.java -d mvn:com.googlecode.json-simple:json-simple:1.1.1 --property quarkus.http.port=64302 -d camel:camel-quarkus-microprofile-health /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/notebooks/DOFramework/inputs-file-source.yaml\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15053)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15053)\u001b[0m Integration inputs-file-source is ready.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15726)\u001b[0m Exec command =>  /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/rayvens/core/harness.py kamel local run --property quarkus.http.port=65299 -d camel:camel-quarkus-microprofile-health /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/notebooks/DOFramework/objectives-file-sink.yaml\n",
            "\u001b[2m\u001b[36m(inner pid=15734)\u001b[0m (input) INFO ... Process successfully extracted event of type json.\n",
            "\u001b[2m\u001b[36m(inner pid=15734)\u001b[0m (input) INFO ... Process working on event input_basic.json.\n",
            "\u001b[2m\u001b[36m(inner pid=15734)\u001b[0m (input) INFO ... Process working on event input_basic.json will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/objectives.\n",
            "\u001b[2m\u001b[36m(inner pid=15734)\u001b[0m (input) INFO ... Process will write 3 products of event input_basic.json to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/objectives.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15726)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15726)\u001b[0m Integration objectives-file-sink is ready.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15726)\u001b[0m Exec command =>  /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/rayvens/core/harness.py kamel local run /usr/local/lib/python3.8/dist-packages/rayvens/core/FileQueue.java /usr/local/lib/python3.8/dist-packages/rayvens/core/FileQueueName.java -d mvn:com.googlecode.json-simple:json-simple:1.1.1 --property quarkus.http.port=49752 -d camel:camel-quarkus-microprofile-health /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/notebooks/DOFramework/objectives-file-source.yaml\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15726)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=15726)\u001b[0m Integration objectives-file-source is ready.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=16699)\u001b[0m Exec command =>  /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/rayvens/core/harness.py kamel local run --property quarkus.http.port=64447 -d camel:camel-quarkus-microprofile-health /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/notebooks/DOFramework/data-file-sink.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-05 12:33:35,073\tWARNING worker.py:1851 -- WARNING: 8 PYTHON worker processes have been started on node: 83c511f1b2d2fd5c45ab49a8997ebafcef9e7bde121d8c16227f2068 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(inner pid=16730)\u001b[0m (objective) INFO ... Process successfully extracted event of type json.\n",
            "\u001b[2m\u001b[36m(inner pid=16730)\u001b[0m (objective) INFO ... Process working on event objective_sfzqd8i6.json.\n",
            "\u001b[2m\u001b[36m(inner pid=16730)\u001b[0m (objective) INFO ... Process working on event objective_sfzqd8i6.json will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/data.\n",
            "\u001b[2m\u001b[36m(inner pid=16730)\u001b[0m (objective) INFO ... Process will write 3 products of event objective_sfzqd8i6.json to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-05 12:33:36,956\tWARNING worker.py:1851 -- WARNING: 12 PYTHON worker processes have been started on node: 83c511f1b2d2fd5c45ab49a8997ebafcef9e7bde121d8c16227f2068 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(inner pid=16777)\u001b[0m (objective) INFO ... Process successfully extracted event of type json.\n",
            "\u001b[2m\u001b[36m(inner pid=16777)\u001b[0m (objective) INFO ... Process working on event objective_g10svyls.json.\n",
            "\u001b[2m\u001b[36m(inner pid=16777)\u001b[0m (objective) INFO ... Process working on event objective_g10svyls.json will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/data.\n",
            "\u001b[2m\u001b[36m(inner pid=16777)\u001b[0m (objective) INFO ... Process will write 3 products of event objective_g10svyls.json to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/data.\n",
            "\u001b[2m\u001b[36m(inner pid=16731)\u001b[0m (objective) INFO ... Process successfully extracted event of type json.\n",
            "\u001b[2m\u001b[36m(inner pid=16731)\u001b[0m (objective) INFO ... Process working on event objective_hjiv5cj9.json.\n",
            "\u001b[2m\u001b[36m(inner pid=16731)\u001b[0m (objective) INFO ... Process working on event objective_hjiv5cj9.json will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/data.\n",
            "\u001b[2m\u001b[36m(inner pid=16731)\u001b[0m (objective) INFO ... Process will write 3 products of event objective_hjiv5cj9.json to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-02-05 12:33:38,322\tWARNING worker.py:1851 -- WARNING: 14 PYTHON worker processes have been started on node: 83c511f1b2d2fd5c45ab49a8997ebafcef9e7bde121d8c16227f2068 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
            "2023-02-05 12:33:39,779\tWARNING worker.py:1851 -- WARNING: 16 PYTHON worker processes have been started on node: 83c511f1b2d2fd5c45ab49a8997ebafcef9e7bde121d8c16227f2068 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
            "2023-02-05 12:34:04,107\tWARNING worker.py:1851 -- WARNING: 20 PYTHON worker processes have been started on node: 83c511f1b2d2fd5c45ab49a8997ebafcef9e7bde121d8c16227f2068 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
            "2023-02-05 12:34:28,186\tWARNING worker.py:1851 -- WARNING: 22 PYTHON worker processes have been started on node: 83c511f1b2d2fd5c45ab49a8997ebafcef9e7bde121d8c16227f2068 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
            "2023-02-05 12:35:00,027\tWARNING worker.py:1851 -- WARNING: 24 PYTHON worker processes have been started on node: 83c511f1b2d2fd5c45ab49a8997ebafcef9e7bde121d8c16227f2068 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(StreamActor pid=16699)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=16699)\u001b[0m Integration data-file-sink is ready.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=16699)\u001b[0m Exec command =>  /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/rayvens/core/harness.py kamel local run /usr/local/lib/python3.8/dist-packages/rayvens/core/FileQueue.java /usr/local/lib/python3.8/dist-packages/rayvens/core/FileQueueName.java -d mvn:com.googlecode.json-simple:json-simple:1.1.1 --property quarkus.http.port=63407 -d camel:camel-quarkus-microprofile-health /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/notebooks/DOFramework/data-file-source.yaml\n",
            "\u001b[2m\u001b[36m(StreamActor pid=16699)\u001b[0m [Kamel subprocess] Kamel `local run` command finished successfully.\n",
            "\u001b[2m\u001b[36m(StreamActor pid=16699)\u001b[0m Integration data-file-source is ready.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process working on event data_sfzqd8i6_ict3ykwu.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process working on event data_sfzqd8i6_ict3ykwu.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process will write 1 products of event data_sfzqd8i6_ict3ykwu.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process working on event data_sfzqd8i6_1xbe1ze1.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process working on event data_sfzqd8i6_1xbe1ze1.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process will write 1 products of event data_sfzqd8i6_1xbe1ze1.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process working on event data_g10svyls_tosrl9zn.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process working on event data_g10svyls_tosrl9zn.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process will write 1 products of event data_g10svyls_tosrl9zn.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process working on event data_g10svyls_fmxgi54u.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process working on event data_g10svyls_fmxgi54u.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process will write 1 products of event data_g10svyls_fmxgi54u.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process working on event data_sfzqd8i6_79dryq6l.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process working on event data_sfzqd8i6_79dryq6l.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19405)\u001b[0m (data) INFO ... Process will write 1 products of event data_sfzqd8i6_79dryq6l.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process working on event data_hjiv5cj9_d32q3rv0.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process working on event data_hjiv5cj9_d32q3rv0.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19442)\u001b[0m (data) INFO ... Process will write 1 products of event data_hjiv5cj9_d32q3rv0.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process working on event data_g10svyls_fszijr72.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process working on event data_g10svyls_fszijr72.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process will write 1 products of event data_g10svyls_fszijr72.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process working on event data_hjiv5cj9_9ps2vr8y.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process working on event data_hjiv5cj9_9ps2vr8y.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19406)\u001b[0m (data) INFO ... Process will write 1 products of event data_hjiv5cj9_9ps2vr8y.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process successfully extracted event of type csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process working on event data_hjiv5cj9_7fzj64nc.csv.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process working on event data_hjiv5cj9_7fzj64nc.csv will write to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n",
            "\u001b[2m\u001b[36m(inner pid=19471)\u001b[0m (data) INFO ... Process will write 1 products of event data_hjiv5cj9_7fzj64nc.csv to bucket /content/drive/.shortcut-targets-by-id/1J90aP5_3HuZJ1pEJWAjeeX4vrlNXSbbl/ocl_lab/data/dof-simulation/solutions.\n"
          ]
        }
      ],
      "source": [
        "dof.run(ocl_resolved, configs_path, objectives=objectives_num, datasets=datasets_num, feasibility_regions=feasibility_regions_num, after_idle_for=20)"
      ],
      "id": "3e353b5c"
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs = storage.count(buckets['inputs'],'json')+storage.count(buckets['inputs_dest'],'json')\n",
        "num_objectives = storage.count(buckets['objectives'],'json')+storage.count(buckets['objectives_dest'],'json')\n",
        "num_datasets = storage.count(buckets['data'],'csv')+storage.count(buckets['data_dest'],'csv')\n",
        "num_solutions = storage.count(buckets['solutions'],'json')\n",
        "\n",
        "print(f'Generated {num_objectives} objectives out of expected {expected_objectives_num}.')\n",
        "print(f'Generated {num_datasets} datasets out of expected {expected_datasets_num}.')\n",
        "print(f'Generated {num_solutions} solutions out of expected {expected_solutions_num}.')"
      ],
      "metadata": {
        "id": "UhxLwnnAV7LH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633c2807-d604-4a95-9fc1-37ef47e3595f"
      },
      "id": "UhxLwnnAV7LH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 3 objectives out of expected 3.\n",
            "Generated 9 datasets out of expected 9.\n",
            "Generated 9 solutions out of expected 9.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}