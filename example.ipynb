{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ordavidov/ocl_lab/blob/aaai/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mva-gAsP09Fp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Mva-gAsP09Fp"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/ocl_lab/notebooks/DOFramework"
      ],
      "metadata": {
        "id": "svXbqbY6_d6K"
      },
      "execution_count": null,
      "outputs": [],
      "id": "svXbqbY6_d6K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOFramework Setup\n",
        "\n",
        "*****\n",
        "\n",
        "We begin by installing the Python package [`doframework`](https://github.com/IBM/doframework). If you are getting errors, restart the runtime and run this cell again (the errors are due to mismatches between Google Colab built-in environment packages and `doframework` requirements that cannot be automatically resolved)."
      ],
      "metadata": {
        "id": "dHNPlukQIOiZ"
      },
      "id": "dHNPlukQIOiZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iCJwvFRsdi3"
      },
      "outputs": [],
      "source": [
        "%pip install doframework"
      ],
      "id": "8iCJwvFRsdi3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb13acad"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field, InitVar\n",
        "from typing import Any\n",
        "import itertools as it\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial import ConvexHull\n",
        "from scipy.stats import uniform\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from doframework.core.pwl import PWL\n",
        "from doframework.core.sampler import D_sampler as sampler\n",
        "from doframework.core.triangulation import box_iterator\n",
        "from doframework.core.hit_and_run import in_domain\n",
        "from doframework.core.utils import sample_standard_simplex, incidence\n",
        "from doframework.core.storage import Storage\n",
        "from doframework.core.inputs import get_configs"
      ],
      "id": "fb13acad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`doframework` relies on [`rayvens`](https://github.com/project-codeflare/rayvens) for event streaming over [`camel`](https://github.com/apache/camel-k/releases?page=3) and on the event distribution framework [`ray`](https://www.ray.io/). To use the `camel` framework, we need to install it together with [JDK](https://www.oracle.com/java/technologies/downloads/) and [`maven`](https://maven.apache.org/)."
      ],
      "metadata": {
        "id": "vl0xfWcaKRIv"
      },
      "id": "vl0xfWcaKRIv"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/apache/camel-k/releases/download/v1.5.1/camel-k-client-1.5.1-linux-64bit.tar.gz\n",
        "!tar zxvf camel-k-client-1.5.1-linux-64bit.tar.gz\n",
        "!cp ./kamel /usr/local/bin\n",
        "!kamel version\n",
        "\n",
        "def install_java():\n",
        "\n",
        "  !apt update\n",
        "  !apt-get install -y openjdk-11-jdk-headless -qq\n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "  !apt-get install -y maven \n",
        "  !java -version\n",
        "  !mvn -version\n",
        "  \n",
        "install_java()"
      ],
      "metadata": {
        "id": "L9cNYGWZU5v9"
      },
      "execution_count": null,
      "outputs": [],
      "id": "L9cNYGWZU5v9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCAsAj1vuQFZ"
      },
      "outputs": [],
      "source": [
        "tol = 1e-8 # tolerance to near 0"
      ],
      "id": "rCAsAj1vuQFZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d490dbde"
      },
      "outputs": [],
      "source": [
        "def triangulate(fpoints: np.array, opoints: np.array, fvals: np.array, ovals: np.array):\n",
        "    \n",
        "    assert all([fpoints.shape[0]==fvals.flatten().size,opoints.shape[0]==ovals.flatten().size]), 'Length of values array should match the number of row vectors.'\n",
        "\n",
        "    m = fpoints.min()\n",
        "    M = fpoints.max()\n",
        "\n",
        "    olift = np.hstack([opoints,(np.random.rand(opoints.shape[0])*(M-m)+m)[:,None]])\n",
        "    flift = np.hstack([fpoints,(np.random.rand(fpoints.shape[0])*(M-m)+11*(M-m)+m)[:,None]]) \n",
        "\n",
        "    P = np.vstack([opoints,fpoints])\n",
        "    _, unique_indices = np.unique(P, axis=0, return_index=True) \n",
        "    Plift = np.vstack([olift,flift])[unique_indices]\n",
        "\n",
        "    view_point = np.concatenate([P.mean(axis=0),np.array([m-1000*(M-m)])]) \n",
        "    envelope = ConvexHull(np.vstack([np.atleast_2d(view_point),Plift]),qhull_options='QG0')\n",
        "    good_indices = envelope.simplices[envelope.good]\n",
        "    fPs = envelope.points[good_indices,:][:,:,:-1]\n",
        "\n",
        "    V = np.concatenate([ovals,fvals])[unique_indices]\n",
        "    fVs = V[:,None][good_indices-1].reshape(*good_indices.shape) # view point at index 0\n",
        "\n",
        "    oin = [np.all(incidence(opoints,fp).any(axis=0)) for fp in fPs]\n",
        "    oPs = fPs[oin]\n",
        "    oVs = fVs[oin]\n",
        "\n",
        "    if oPs.size == 0: # when fail to catch omega lower envelope\n",
        "        oPs, oVs = fPs, fVs\n",
        "\n",
        "    return fPs, fVs, oPs, oVs"
      ],
      "id": "d490dbde"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ddb5500"
      },
      "source": [
        "# DOFramework Example\n",
        "\n",
        "*****\n",
        "\n",
        "This notebook will demo ```doframework``` on a naive Optimization with Constraint Learning (OCL) algorithm. Ideally, ```doframework``` will be used against a more sophisticated OCL algorithm, such as [OptiCL](https://github.com/hwiberg/OptiCL), to check its effectiveness. \n",
        "\n",
        "`doframework` randomly generates optimization problem instances $(f,\\Omega,D,\\mathbf{x}^*)$ for the OCL algorithm to solve. These optimization problem instances include:\n",
        "* $f: \\mathbb{R}^d → \\mathbb{R}$ a continuous piece-wise linear objective.\n",
        "* $\\Omega ⊆ \\mathbb{R}^d$ a feasibility region as a bounded convex $d$-polytope.\n",
        "* $D = (X,y)$ data associated with $f$ so that $X ⊆ \\mbox{dom}(f)$ and $y = f(\\mathbf{x}) + ϵ$, $ϵ \\sim \\mathcal{N}(0,σ^2)$.\n",
        "* $\\mathbf{x}^* = \\arg \\min_{\\mathbf{x} \\in Ω} f(\\mathbf{x})$ the ground-truth optimum.\n",
        "\n",
        "`doframework` feeds $(\\Omega,D)$ to a user-provided OCL algorithm. It then collects its predicted optimum $\\hat{\\mathbf{x}}^*$ to compare against $\\mathbf{x}^*$.\n",
        "\n",
        "This notebook is divided into two parts. In <font color=green>Part I</font> we will define a naive OCL algorithm and test it. Here, we will work with a PWL object, which is the fundamental object ```doframework``` uses to generate constraints and data.\n",
        "\n",
        "Once we have tested our OCL algorithm, we will switch to <font color=green>Part II</font>, where we will demonstrate running ```doframework``` on our algorithm."
      ],
      "id": "7ddb5500"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd70fe60"
      },
      "source": [
        "# Part I\n",
        "\n",
        "*****\n",
        "\n",
        "## -- Objective\n",
        "\n",
        "We will first define a _test_ objective target to use against our naive OCL algorithm. We will define the objective target as a PWL object, similarly to the way ```doframework``` does it (only for more sophisticated PWL functions).\n",
        "\n",
        "The domain of the objective function we'll use will be a ```box```."
      ],
      "id": "bd70fe60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0570b693"
      },
      "outputs": [],
      "source": [
        "box = [[-1,1],[-1,1],[-1,1],[-1,1]]"
      ],
      "id": "0570b693"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "938d1a23"
      },
      "outputs": [],
      "source": [
        "fpoints = np.vstack(list(map(np.array, it.product(*box))))\n",
        "fhull = ConvexHull(fpoints,qhull_options='QJ')\n",
        "dim = fpoints.shape[-1]"
      ],
      "id": "938d1a23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d430afee"
      },
      "source": [
        "Our test function will be affine, determined by coefficients $\\mathbf{a}$ and intercept $b$,\n",
        "$$f(\\mathbf{x}) = \\mathbf{a}^T\\mathbf{x} + b.$$\n",
        "We encode function $f$ by an array $(\\mathbf{a},b)$."
      ],
      "id": "d430afee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ea305c6"
      },
      "outputs": [],
      "source": [
        "ab = np.concatenate([np.ones(dim),np.zeros(1)])"
      ],
      "id": "1ea305c6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39407f1d"
      },
      "source": [
        "and evaluate $f$ at the vertices of $\\mbox{dom}(f)$."
      ],
      "id": "39407f1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e923df2"
      },
      "outputs": [],
      "source": [
        "fvals = np.pad(fpoints,[(0,0),(0,1)],constant_values=1) @ ab"
      ],
      "id": "8e923df2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221e2260"
      },
      "source": [
        "## -- Constraints\n",
        "\n",
        "We will now define _test_ constraints as well. The randomly generated constraints we'll use define a convex polytope $\\Omega$ inside $\\mbox{dom}(f)$. \n",
        "\n",
        "More generally, ```doframework``` randomly generates constraints as convex polytopes within its randomly generated PWL functions' domains.\n",
        "\n",
        "We choose a range of coordinate values within which to sample the vertices of $\\Omega$."
      ],
      "id": "221e2260"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a72eb22e"
      },
      "outputs": [],
      "source": [
        "omega_range = [[-0.5,1],[-1,0.5],[-1,1],[-1,1]]"
      ],
      "id": "a72eb22e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eae2f001"
      },
      "outputs": [],
      "source": [
        "omega_vertex_num = 10"
      ],
      "id": "eae2f001"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dff9634f"
      },
      "source": [
        "We'll sample vertics for $\\Omega$ within $\\mbox{dom}(f)$."
      ],
      "id": "dff9634f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9df74df"
      },
      "outputs": [],
      "source": [
        "opoints = np.vstack(\n",
        "    list(\n",
        "        it.islice(\n",
        "            filter(lambda point: in_domain(np.atleast_2d(point), fhull.equations, tol=tol)[0],\n",
        "                box_iterator(omega_range,1)),\n",
        "            omega_vertex_num)\n",
        "    )\n",
        ")\n",
        "\n",
        "ovals = np.pad(opoints,[(0,0),(0,1)],constant_values=1) @ ab"
      ],
      "id": "d9df74df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1b23a13"
      },
      "source": [
        "## -- PWL Object\n",
        "\n",
        "We're now ready to define a PWL object that will serve us to generate data.\n",
        "\n",
        "A PWL object relies on a triangulation of $\\mbox{dom}(f)$ that incorporates $\\Omega$."
      ],
      "id": "c1b23a13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "421bcdd8"
      },
      "outputs": [],
      "source": [
        "fPs, fVs, oPs, oVs = triangulate(fpoints,opoints,fvals,ovals)"
      ],
      "id": "421bcdd8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "873b2ef8"
      },
      "outputs": [],
      "source": [
        "f = PWL(fPs,fVs)"
      ],
      "id": "873b2ef8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bd2d762"
      },
      "outputs": [],
      "source": [
        "ohull = ConvexHull(np.vstack(oPs),qhull_options='QJ')\n",
        "constraints = np.unique(ohull.equations,axis=0)"
      ],
      "id": "6bd2d762"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a029407"
      },
      "outputs": [],
      "source": [
        "f_value_interval = [np.array(fVs).min(),np.array(fVs).max()]\n",
        "f_value_range = f_value_interval[1]-f_value_interval[0]"
      ],
      "id": "3a029407"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d341c7de"
      },
      "source": [
        "We can use the PWL object $f$ to sample points in its domain."
      ],
      "id": "d341c7de"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c185e381"
      },
      "outputs": [],
      "source": [
        "xs = f.sample(3)"
      ],
      "id": "c185e381"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80c387f3"
      },
      "source": [
        "or evaluate points"
      ],
      "id": "80c387f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52e1182c"
      },
      "outputs": [],
      "source": [
        "f.evaluate(xs)"
      ],
      "id": "52e1182c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a632859c"
      },
      "source": [
        "## -- Ground Truth\n",
        "\n",
        "Since we have a triangulation of $f$ and $\\Omega$, we also have immediate knowledge of the ground truth. We will later compare it to our naive OCL algorithm's results."
      ],
      "id": "a632859c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df8ed6a3"
      },
      "outputs": [],
      "source": [
        "argmin = np.argmin(oVs)"
      ],
      "id": "df8ed6a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31aa42bb"
      },
      "outputs": [],
      "source": [
        "j = argmin % oVs.shape[-1]"
      ],
      "id": "31aa42bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93286523"
      },
      "outputs": [],
      "source": [
        "i = int(argmin/oVs.shape[-1])"
      ],
      "id": "93286523"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19c295d7"
      },
      "outputs": [],
      "source": [
        "opt_true = oPs[i][j]"
      ],
      "id": "19c295d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "144d0ed1"
      },
      "outputs": [],
      "source": [
        "opt_true_val = f.evaluate(np.atleast_2d(opt_true))[0]"
      ],
      "id": "144d0ed1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b727caa"
      },
      "source": [
        "## -- Data\n",
        "\n",
        "We'll now generate data from the test objective target $f$. The data we'll sample will be a Gaussian mix in $\\mbox{dom}(f)$. \n",
        "\n",
        "Let's decide how many Gaussians we want in the mix."
      ],
      "id": "3b727caa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65b88609"
      },
      "outputs": [],
      "source": [
        "mean_num = 3"
      ],
      "id": "65b88609"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df3ea6c4"
      },
      "source": [
        "and how much noise to add to functions values in relative terms (```noise=0.05``` means $5\\%$ of $f$ value range in $\\mbox{dom}(f)$)."
      ],
      "id": "df3ea6c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb4a1602"
      },
      "outputs": [],
      "source": [
        "noise = 0.05"
      ],
      "id": "bb4a1602"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8194728b"
      },
      "source": [
        "We'll sample some means for the Gaussians in the mix from $\\mbox{dom}(f)$."
      ],
      "id": "8194728b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76c948a9"
      },
      "outputs": [],
      "source": [
        "samples = f.sample(mean_num)"
      ],
      "id": "76c948a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9297899c"
      },
      "outputs": [],
      "source": [
        "means = [s for s in samples]"
      ],
      "id": "9297899c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2267b8a8"
      },
      "source": [
        "and sample some non-spherical covariance matrices."
      ],
      "id": "2267b8a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3c4dd39"
      },
      "outputs": [],
      "source": [
        "covs = [np.diag(uniform.rvs(f_value_interval[0],f_value_range,dim)**2)*np.eye(dim) for _ in range(mean_num)]"
      ],
      "id": "d3c4dd39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f872ca3"
      },
      "source": [
        "We'll also sample ```weights``` for the Gaussians in the mix."
      ],
      "id": "4f872ca3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ed58cdc"
      },
      "outputs": [],
      "source": [
        "weights = sample_standard_simplex(mean_num)"
      ],
      "id": "4ed58cdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82c845dc"
      },
      "source": [
        "We'll decide on the number of data points $N$ to sample."
      ],
      "id": "82c845dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bff16cf"
      },
      "outputs": [],
      "source": [
        "N = 750"
      ],
      "id": "5bff16cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12847e06"
      },
      "source": [
        "and finally get some samples."
      ],
      "id": "12847e06"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "215be556"
      },
      "outputs": [],
      "source": [
        "D = sampler(f, N, weights, noise*(f_value_range), mean=means, cov=covs, num_cpus=4)"
      ],
      "id": "215be556"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28840f47"
      },
      "source": [
        "We'll make sure all data points are indeed in $\\mbox{dom}(f)$."
      ],
      "id": "28840f47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4ab9d94"
      },
      "outputs": [],
      "source": [
        "np.all(f.isin(D[:,:-1]))"
      ],
      "id": "d4ab9d94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ed46fa"
      },
      "source": [
        "## -- Model"
      ],
      "id": "b9ed46fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2eb6799"
      },
      "source": [
        "Let's build a simple model class for the predict component of our OCL algorithm.\n",
        "\n",
        "There is only _one_ requirement on the model class instance: it should have a ``predict`` method that accepts and returns ``np.array``'s.\n",
        "\n",
        "The rest is up to us. We can add any attribute like. It will be added to the solution file generated by ``doframework``."
      ],
      "id": "e2eb6799"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36bc427e"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class predictionModel:\n",
        "    '''\n",
        "    Class for the prediction model of an OCL algorithm.\n",
        "    '''\n",
        "        \n",
        "    model = LinearRegression()\n",
        "    data: InitVar[np.array] = None\n",
        "    r2_score: float = field(init=False)\n",
        "        \n",
        "    def __post_init__(self,data):\n",
        "        if data is not None:\n",
        "            self.model.fit(data[:,:-1], data[:,-1])\n",
        "            self.r2_score = self.model.score(data[:,:-1], data[:,-1])\n",
        "\n",
        "    def predict(self, x: np.array) -> np.array:\n",
        "        return self.model.predict(x)\n"
      ],
      "id": "36bc427e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd48e7b5"
      },
      "outputs": [],
      "source": [
        "model = predictionModel(D)"
      ],
      "id": "dd48e7b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8012c7"
      },
      "source": [
        "## -- Solver\n",
        "\n",
        "The solver class will be responsible for the optimization part of the OCL algorithm.\n",
        "\n",
        "This particular solver class is designed to work with a simple linear regressor. It uses the [PuLP solver](https://coin-or.github.io/pulp/# \"PuLP\")."
      ],
      "id": "bd8012c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37f214cc"
      },
      "outputs": [],
      "source": [
        "from pulp import *"
      ],
      "id": "37f214cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e513a87a"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class optimizationModel:\n",
        "    '''\n",
        "    Class for the solver of an OCL algorithm.\n",
        "    '''\n",
        "\n",
        "    predict: InitVar[Any]\n",
        "    objective_target: np.array = field(init=False)\n",
        "        \n",
        "    def __post_init__(self,predict):\n",
        "        self.objective_target = np.concatenate((predict.model.coef_.reshape(-1,1), \n",
        "                                                predict.model.intercept_.reshape(-1,1)))\n",
        "        self.objective_target = self.objective_target.flatten()\n",
        "\n",
        "    def optimize(self,constraints,is_minimum) -> np.array:\n",
        "        \n",
        "        n = self.objective_target.shape[-1]\n",
        "        variables = [*range(n)]\n",
        "        x = LpVariable.dicts(\"x\", variables)\n",
        "\n",
        "        prob = LpProblem(\"Optimization\",LpMinimize) if is_minimum else LpProblem(\"Optimization\",LpMaximize)\n",
        "        prob += lpSum([self.objective_target[i] * x[i] for i in variables]), \"Objective Target\"\n",
        "        prob += x[n-1] == 1, \"Intercept\"\n",
        "\n",
        "        for k, eqn in enumerate(constraints):\n",
        "            prob += (\n",
        "                pulp.lpSum([eqn[i]*x[i] for i in variables]) <= 0,\n",
        "                f\"constraint_from_{k}th_facet\",\n",
        "            )\n",
        "        prob.solve(PULP_CBC_CMD(msg=0)) # disable logs with msg=0\n",
        "\n",
        "        return np.array([v.varValue for v in prob.variables()],dtype=np.float32)[:-1] # remove intercept coord\n"
      ],
      "id": "e513a87a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa7542b3"
      },
      "outputs": [],
      "source": [
        "solver = optimizationModel(model)\n",
        "opt_pred = solver.optimize(constraints,is_minimum=True)\n",
        "opt_pred_val = model.predict(np.atleast_2d(opt_pred))[0]    "
      ],
      "id": "fa7542b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d605964"
      },
      "outputs": [],
      "source": [
        "print(f'True optimum: {opt_true}\\nPredicted optimum: {opt_pred}\\nTrue optimal values: {opt_true_val}\\nPredicted optimal value: {opt_pred_val}')"
      ],
      "id": "4d605964"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4120e741"
      },
      "source": [
        "# Part II\n",
        "\n",
        "****\n",
        "\n",
        "## -- OCL Algorithm\n",
        "\n",
        "Now that we tested our naive OCL algorithm, we can package it as a function that ```doframework``` can integrate into its flow.\n",
        "\n",
        "Our function should accept ``data`` and ``constraints`` as input and produce an ``optimum`` with its predicted ``value`` as well as a ``model`` that was used in the predict phase."
      ],
      "id": "4120e741"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "506bf769"
      },
      "outputs": [],
      "source": [
        "import doframework as dof"
      ],
      "id": "506bf769"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d46d5c0"
      },
      "outputs": [],
      "source": [
        "def ocl(data: np.array, constraints: np.array, **kwargs):\n",
        "\n",
        "    is_minimum = kwargs['is_minimum'] if 'is_minimum' in kwargs else True\n",
        "                \n",
        "    try:\n",
        "\n",
        "        data_feasible = data[np.all(np.pad(data[:,:-1],((0,0),(0,1)),constant_values=1) @ constraints.T <= 0, axis=1)]\n",
        "        model = predictionModel(data_feasible)\n",
        "        solver = optimizationModel(model)\n",
        "        optimum = solver.optimize(constraints,is_minimum)\n",
        "        predicted_value = model.predict(np.atleast_2d(optimum))[0]    \n",
        "\n",
        "    except Exception as e:\n",
        "      \n",
        "        print('Exception: Prediction optimization failed.')\n",
        "        print(e)\n",
        "        return None, None, None\n",
        "\n",
        "    else:\n",
        "\n",
        "        return optimum, predicted_value, model"
      ],
      "id": "7d46d5c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9952dfd"
      },
      "source": [
        "To integrate our simple algorithm into ```doframework```, we need to **resolve** it."
      ],
      "id": "f9952dfd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5af09629"
      },
      "outputs": [],
      "source": [
        "@dof.resolve\n",
        "def ocl_resolved(data: np.array, constraints: np.array, **kwargs):\n",
        "    return ocl(data, constraints, **kwargs)"
      ],
      "id": "5af09629"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f636898"
      },
      "source": [
        "## -- Configs\n",
        "\n",
        "`doframework` relies on a configs yaml to enable its interaction with storage. Storage can be S3 buckets (AWS / IBM Cloud) or a local file system. Here, we will rely on local storage. We already uploaded `sim_configs.yaml` to our `ocl_lab` directory. Here is what it looks like:\n",
        "```\n",
        "local:\n",
        "  buckets: \n",
        "    inputs: '../ocl_lab/data/dof-simulation/inputs'\n",
        "    inputs_dest: '../ocl_lab/data/dof-simulation/inputs-dest'\n",
        "    objectives: '../ocl_lab/data/dof-simulation/objectives'\n",
        "    objectives_dest: '../ocl_lab/data/dof-simulation/objectives-dest'\n",
        "    data: '../ocl_lab/data/dof-simulation/data'\n",
        "    data_dest: '../ocl_lab/data/dof-simulation/data-dest'\n",
        "    solutions: '../ocl_lab/data/dof-simulation/solutions'\n",
        "```\n",
        "\n",
        "Each `doframework` simulation product type has a _source_ bucket and a _target_ bucket underscored with `_dest`. At the end of a `doframework` run, you will find all simulation products in their `_dest` folders, except for algorithm solution files which will be under the `solutions` bucket.\n",
        "\n",
        "We must make sure the bucket nanes we provide are **DISTINCT**. You will find all accepted configuration formats under [`doframework/configs`](https://github.com/IBM/doframework/tree/main/configs). "
      ],
      "id": "5f636898"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69b5c623"
      },
      "outputs": [],
      "source": [
        "root = os.getcwd()\n",
        "configs_file = 'sim_configs.yaml'\n",
        "configs_path = os.path.join(root,configs_file)\n",
        "\n",
        "sim_configs = get_configs(configs_path)\n",
        "storage = Storage(sim_configs)\n",
        "buckets = storage.buckets()"
      ],
      "id": "69b5c623"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a5ab5ea"
      },
      "source": [
        "## -- Inputs\n",
        "\n",
        "To run `doframework`, we need input json files with meta data for `doframework` to generate objectives, constraints, and datasets. Here is an example of `input_basic.json` uploaded to `ocl_lab/notebooks/DOFramework`:\n",
        "```\n",
        "{\n",
        "    \"f\": {\n",
        "        \"vertices\": {\n",
        "            \"num\": 20,\n",
        "            \"range\": [[0.0,10.0],[0.0,10.0],[0.0,10.0],[0.0,10.0],[0.0,10.0]]\n",
        "        },\n",
        "        \"values\": {\n",
        "            \"range\": [-10.0,10.0]\n",
        "        }\n",
        "    },\n",
        "    \"omega\": {\n",
        "        \"ratio\": 0.6\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"N\": 1000,\n",
        "        \"noise\": 0.01,\n",
        "        \"policy_num\": 3,\n",
        "        \"scale\": 0.7\n",
        "    },\n",
        "    \"input_file_name\": \"input_basic.json\"\n",
        "}\n",
        "``` \n",
        "\n"
      ],
      "id": "7a5ab5ea"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's copy `input_basic.json` to the `inputs` bucket specified in `sim_configs.yaml`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8XLwyBO8AEgk"
      },
      "id": "8XLwyBO8AEgk"
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = 'input_basic.json'\n",
        "input_path = os.path.join(buckets['inputs'],input_file)\n",
        "\n",
        "shutil.copyfile(input_file, input_path)"
      ],
      "metadata": {
        "id": "c3-_rzgu_J8s"
      },
      "id": "c3-_rzgu_J8s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This input file tells `doframework` to generate continuous piece-wise linear functions supported in `f[vertices][range]` $\\subseteq \\mathbb{R}^5$ with `f[vertices][num]` vertices (more vertices -> more complex functions). $f(\\mathbf{x})$ values will be bounded in `f[values][range]`. \n",
        "\n",
        "This input file tells ```doframework``` to generate a polytope of constraints $\\Omega$ that covers at least ```omega[ratio]``` of $\\mbox{dom}(f)$. It tells `doframework` to generate `data[N]` points in each dataset as a Gaussian mix with `data[policy_num]` centers. The maximum length scale for each Gaussian will be at most `data[scale]` of $\\mbox{dom}(f)$ diameter. Noise will be introduced to $f$ values with STD  of `data[noise]`$\\cdot$`f[values][range]`.\n",
        "You will find accepted input formats under [`doframework/inputs`](https://github.com/IBM/doframework/tree/main/inputs). "
      ],
      "metadata": {
        "id": "jQN1rNfs_IN0"
      },
      "id": "jQN1rNfs_IN0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aabc20e9"
      },
      "source": [
        "## -- Run\n",
        "\n",
        "We are finally ready to run `doframework`. `doframework` will generate a specified number of objectives, constraints (i.e., feasibility regions), and datasets, and then run them against `ocl_resolved`."
      ],
      "id": "aabc20e9"
    },
    {
      "cell_type": "code",
      "source": [
        "objectives_num = 3\n",
        "feasibility_regions_num = 1\n",
        "datasets_num = 3"
      ],
      "metadata": {
        "id": "jBvpufl1VmLJ"
      },
      "id": "jBvpufl1VmLJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs_at_start = storage.count(buckets['inputs'],'json')+storage.count(buckets['inputs_dest'],'json')\n",
        "num_objectives_at_start = storage.count(buckets['objectives'],'json')+storage.count(buckets['objectives_dest'],'json')\n",
        "num_datasets_at_start = storage.count(buckets['data'],'csv')+storage.count(buckets['data_dest'],'csv')\n",
        "num_solutions_at_start = storage.count(buckets['solutions'],'json')\n",
        "\n",
        "expected_objectives_num = objectives_num\n",
        "expected_datasets_num = expected_objectives_num*datasets_num\n",
        "expected_solutions_num = expected_datasets_num*feasibility_regions_num"
      ],
      "metadata": {
        "id": "pXVQF0ndVCJ7"
      },
      "id": "pXVQF0ndVCJ7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e353b5c"
      },
      "outputs": [],
      "source": [
        "dof.run(ocl_resolved, configs_path, objectives=objectives_num, datasets=datasets_num, feasibility_regions=feasibility_regions_num, after_idle_for=20)"
      ],
      "id": "3e353b5c"
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs = storage.count(buckets['inputs'],'json')+storage.count(buckets['inputs_dest'],'json')-num_inputs_at_start\n",
        "num_objectives = storage.count(buckets['objectives'],'json')+storage.count(buckets['objectives_dest'],'json')-num_objectives_at_start\n",
        "num_datasets = storage.count(buckets['data'],'csv')+storage.count(buckets['data_dest'],'csv')-num_datasets_at_start\n",
        "num_solutions = storage.count(buckets['solutions'],'json')-num_solutions_at_start\n",
        "\n",
        "print(f'Generated {num_objectives} objectives out of expected {expected_objectives_num}.')\n",
        "print(f'Generated {num_datasets} datasets out of expected {expected_datasets_num}.')\n",
        "print(f'Generated {num_solutions} solutions out of expected {expected_solutions_num}.')"
      ],
      "metadata": {
        "id": "UhxLwnnAV7LH"
      },
      "id": "UhxLwnnAV7LH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}